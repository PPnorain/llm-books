## 值得关注的公司
### 欢迎关注 [LLM 应用全栈开发](https://liduos.com/wxqcode.png)
跟踪LLM(大语言模型)最新动态，分享第一手LLM 实践经验，致力于打造个人LLM 应用开发全栈指南！
### AI infra
1. [Tecton](https://tecton.ai)

    Tecton 是一个 feature store（特征平台），用于创建、存储和管理机器学习工作中的 feature（特征）。如果我们将 AI/ML 模型简单看作一个回归方程，那么特征就是自变量"x"，我们在训练和推理时都需要用到大量特征。Feature store 目前主要用于实时推理场景，使用对象是数据科学家和机器学习工程师。（开源替代[Feast](https://github.com/feast-dev/feast)

2. [Abacus.AI](https://abacus.ai/)提供了一个端到端的自主平台，用于训练自定义深度学习模型并进行部署。

### LLM
1. [Anthropic](https://www.anthropic.com/)

    Anthropic是由OpenAI的前成员创立的专注人工智能安全和研究的初创公司，并秉承负责任的AI使用理念，Claude 聊天机器人背后的研发公司。

2. [Inflection AI](https://inflection.ai/)

### 值得关注的 StartUp
在这个领域的开源项目应该有两次产品市场适应性：1.首先能够在项目周围创造价值和社区；2.其次是在将业务与之结合时，创建一个可靠和适应性强的基础设施和工具层将帮助更多用户和应用释放LLM的潜力和价值。这个只关注和LLM应用栈开发相关的初创公司，我把它称为LLMOps，大致分为以下几个类别：
- 提示管理和评估（提示工程、审核、跟踪、A/B测试、提示链接、调试提示、评估等），包括跨多个基础模型提供商进行提示链接；
- 无代码/低代码微调/嵌入管理（包括用于在特定数据集上重新训练通用模型的工具，标记、清洗等）
- 代理集成/基于行动的LLM决策，执行行动，目标规划，与外部世界接口等；
- 分析/可观察性——成本、延迟、速率限制管理、可解释性等。

1. [PromptLayer](https://promptlayer.com/)

    输入侧 Prompt 管理的工具，后面补充上LLM输出侧的质量监控，优化建议等等，LLM技术栈的运维监控工具。

2. [Rebuff AI](https://rebuff.ai/)

    旨在通过多层防御，保护 AI 应用免受即时注入攻击 —— 第一个系统地用 AI 做注入攻击防御的项目。

3. [Arize AI](https://arize.com)

    通过对模型进行评估、监控以及故障排查，用于确定 LLM 工作过程中需要改进的地方的工具

4. [embedding.store](https://www.embedding.store/)

    具有公共、私有和第三方数据的托管嵌入市场

5. [Whylab](https://whylabs.ai/)

    AI 可观察性平台，消除了模型和数据监控的痛苦，使客户可以花更少的时间在救火上，而将更多的时间花在构建模型上。

6. [Portkey](https://portkey.ai/)

    模型管理和可观测性：管理模型（提示、参数、引擎、版本），查看模型和版本之间的流量和延迟，无需停机，无缝升级。实时查看和调试请求，跟踪用户之间的流量和使用情况，当AI提供商出现故障时，获取状态更新，通过缓存和边缘计算来降低延迟。

7. [Vellum](https://www.vellum.ai/)

    将LLM强大特性与用于提示工程、语义搜索、版本控制、定量测试和性能监控的工具结合，使其投入生产。与所有主要的LLM提供商兼容。

8. [Humanloop](https://humanloop.com/)

    帮助开发者在大型语言模型（如GPT-3）之上构建高性能应用程序。您可以使用它来尝试新的提示，收集模型生成的数据和用户反馈，并对模型进行微调以提高性能并优化成本。

9. [Helicone](https://www.helicone.ai/)

    Helicone是一个开源的可观测性平台，用于记录所有请求到OpenAI的日志，并提供用户友好的UI界面、缓存、自定义速率限制和重试等功能。它可以通过用户和自定义属性跟踪成本和延迟，并为每个日志提供一个游乐场，以在UI中迭代提示和聊天对话。此外，Helicone还提供了Python和Node.JS支持，以及开发者文档和社区支持。