## OpenAI 文档解读
OpenAI 文档涉及内容众多，而且这里已经有了[中文翻译](https://openai.xiniushu.com/)，需要详细了解的可以自行前往阅读。我这里会重点选取高频使用的 API 进行说明以及对Fine-tuning（微调）、Embeddings（嵌入）、GPT best practices（GPT最佳实践）几个主题进行解读。

### API介绍
1. 所有 API 演示均使用 Python 代码作为示例，所以确保已经安装官方 Python 包：`pip install openai`，同时配置 API 密钥的环境变量 `OPENAI_API_KEY`。
2. 认证：OpenAI API 使用 API 密钥进行身份验证， [API密钥页面](https://platform.openai.com/account/api-keys)可以获取使用的 API 密钥。除了密钥，对于属于多个组织的用户，可以传递一个Requesting organization字段（可以在[组织设置](https://platform.openai.com/account/org-settings)页面上找到组织ID）来指定用于 API请求的组织，这些API请求的使用将计入指定组织的订阅配额。

    ```python
    import os
    import openai
    # openai.organization = "org-gth0C8mT2wnKealyDkrSrpQk"
    openai.api_key = os.getenv("OPENAI_API_KEY")
    openai.Model.list()
    ```

#### Chat Completions 会话补全
这个是使用频次最高的接口，几乎当前所有的套壳ChatGPT应用都是基于这个接口封装的，所以将其放在第一个。给定一组描述对话的消息列表，模型将返回一个回复。
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")

# https://api.openai.com/v1/chat/completions
completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "user", "content": "Hello!"}
  ]
)

print(completion.choices[0].message)
```

**响应** ：
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "\n\nHello there, how may I assist you today?",
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

**Request body(常用入参详解)** ：

> - **`model` （string，必填）**
>
>   要使用的模型ID。有关哪些模型适用于Chat API的详细信息，请查看 [模型端点兼容性表](https://platform.openai.com/docs/models/model-endpoint-compatibility)
>
> - **`messages` （array，必填）**
>
>   迄今为止描述对话的消息列表
>
>   - **`role` （string，必填）**
>
>     发送此消息的角色。`system` 、`user` 或 `assistant` 之一（一般用 user 发送用户问题，system 发送给模型提示信息）
>
>   - **`content` （string，必填）**
>
>     消息的内容
>
>   - **`name` （string，选填）**
>
>     此消息的发送者姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符
>
> - **`stream` （boolean，选填，是否按流的方式发送内容）**
>
>   当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。SSE 本质上是一个长链接，会持续不断地输出内容直到完成响应。如果不是做实时聊天，默认false即可。请参考OpenAI Cookbook 以获取 [示例代码](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb)。
>
> - **`max_tokens` （integer，选填）**
>
>   在聊天补全中生成的最大 [tokens](https://platform.openai.com/tokenizer) 数。
>
>   输入token和生成的token的总长度受模型上下文长度的限制。
>
> - **`temperature` （number，选填，默认是 1）**
>
>   采样温度，在 0和 2 之间。
>
>   较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。
>
>   通常建议修改这个（`temperature` ）或者 `top_p` ，但两者不能同时存在，二选一。
>


#### Completions （文本和代码）补全
给定一个提示，模型将返回一个或多个预测的补全，并且还可以在每个位置返回替代 token 的概率。
  ```python
  import os
  import openai
  openai.api_key = os.getenv("OPENAI_API_KEY")
  # https://api.openai.com/v1/completions
  openai.Completion.create(
    model="text-davinci-003",
    prompt="Say this is a test",
    max_tokens=7,
    temperature=0
  )
```

**响应** ：
```json
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "text-davinci-003",
  "choices": [
    {
      "text": "\n\nThis is indeed a test",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

**Request body(入参详解)** ：

> - **`model` （string，必填）**
>
>   要使用的模型的 ID。可以参考 [模型端点兼容性表](https://platform.openai.com/docs/models/model-endpoint-compatibility)
>
> - **`prompt` （string or array，选填，Defaults to <|endoftext|>）**
>
>   生成补全的提示，编码为字符串、字符串数组、token数组或token数组数组。
>
>   注意 <|endoftext|> 是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一样生成。
>
> - **`stream` （boolean，选填，默认 false）**
>
>   当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 `data: [DONE]` 消息终止。
>
> - **`max_tokens` （integer，选填，默认是 16）**
>
>   补全时要生成的最大 [token](https://platform.openai.com/tokenizer) 数。
>
>   提示 `max_tokens` 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个token（最新模型除外，它支持 4096）
>
> - **`temperature` （number，选填，默认是1）**
>
>   使用哪个采样温度，在 **0和2之间**。
>
>   较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。
>
>   通常建议修改这个（`temperature` ）或 `top_p` 但两者不能同时存在，二选一。
>
> - **`n` （integer，选填，默认为 1）**
>
>   每个 `prompt` 生成的补全次数。
>
>   注意：由于此参数会生成许多补全，因此它会快速消耗token配额。小心使用，并确保对 `max_tokens` 和 `stop` 进行合理的设置。
>


#### <a id="embeddings">Embeddings 嵌入</a>
将一个给定输入转换为向量表示，提供给机器学习模型算法使用。
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/embeddings
openai.Embedding.create(
  model="text-embedding-ada-002",
  input="The food was delicious and the waiter..."
)
```

**响应** ：
```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        .... (1536 floats total for ada-002)
        -0.0028842222,
      ],
      "index": 0
    }
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

**Request body(入参详解)** ：

> - **`model` （string，必填）**
>
>   要使用的 **模型ID**，可以参考 [模型端点兼容性表](https://platform.openai.com/docs/models/model-endpoint-compatibility)
>
> - **`input` （string or array，必填）**
>
>   输入文本以获取嵌入，编码为字符串或token数组。要在单个请求中获取多个输入的嵌入，请传递字符串数组或token数组的数组。每个输入长度**不得超过 8192 个token**。
>
> - **`user` （string，选填）**
>
>   一个唯一的标识符，代表终端用户，可以帮助OpenAI检测滥用。
>

#### Fine-tuning 微调
使用自定义的特定训练数据，定制自己的模型。
##### **Create fine-tune**
创建一个微调作业，从给定的数据集中微调指定模型。
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# POST https://api.openai.com/v1/fine-tunes
openai.FineTune.create(training_file="file-XGinujblHPwGLSztz8cPS8XY")
```

**响应**（响应包括已入队的作业的详细信息，包括微调作业状态和完成后微调模型的名称）：
```json
{
  "id": "ft-AF1WoRqd3aJAHsqc9NY7iL8F",
  "object": "fine-tune",
  "model": "curie",
  "created_at": 1614807352,
  "events": [
    {
      "object": "fine-tune-event",
      "created_at": 1614807352,
      "level": "info",
      "message": "Job enqueued. Waiting for jobs ahead to complete. Queue number: 0."
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": 4,
    "learning_rate_multiplier": 0.1,
    "n_epochs": 4,
    "prompt_loss_weight": 0.1,
  },
  "organization_id": "org-...",
  "result_files": [],
  "status": "pending",
  "validation_files": [],
  "training_files": [
    {
      "id": "file-XGinujblHPwGLSztz8cPS8XY",
      "object": "file",
      "bytes": 1547276,
      "created_at": 1610062281,
      "filename": "my-data-train.jsonl",
      "purpose": "fine-tune-train"
    }
  ],
  "updated_at": 1614807352,
}
```

**Request body(入参详解)** ：

> - `training_file` （string，必填）
>
>   包含 **训练数据** 的已上传文件的ID。
>
>   请参阅 [upload file](https://platform.openai.com/docs/api-reference/files/upload) 以了解如何上传文件。
>
>   数据集必须格式化为 **JSONL文件**，其中每个训练示例都是一个带有 “prompt” 和 “completion” keys 的 JSON对象。
>
> - `validation_file` （string，选填）
>
>   包含 **验证数据** 的已上传文件的ID。
>
>   如果提供此文件，则数据将在微调期间定期用于生成验证指标。这些指标可以在 [微调结果文件](https://platform.openai.com/docs/guides/fine-tuning/analyzing-your-fine-tuned-model) 中查看，训练和验证数据应该是互斥的。
>
> - `model` （string，选填，默认是curie）
>
>   要微调的基础模型名称。
>
>   可以选择其中之一："ada"、"babbage"、"curie"、"davinci"，或 2022年4月21日 后创建的经过微调的模型。要了解这些模型的更多信息，请参阅 [Models](https://platform.openai.com/docs/models) 文档。
>
> - `n_epochs` （integer，选填，默认是4）
>
>   训练模型的批次数。一个 epoch 指的是完整地遍历一次训练数据集
>
> - `batch_size` （integer，选填）
>
>   用于训练的批次大小，指的是每次迭代中同时处理的样本数量。
>
>   默认情况下，批次大小将动态配置为训练集示例数量的约 0.2％，上限为256。
>
>   通常，发现较大的批次大小对于更大的数据集效果更好。
>
> - `learning_rate_multiplier` （number，选填）
>
>   用于训练的学习率倍增器。微调学习率是预训练时使用的原始学习率乘以此值得到的（🤖️微调学习率（Learning Rate）指的是神经网络在进行梯度下降优化算法时，每次更新参数的步长。学习率越大，神经网络的参数更新越快，但可能会导致优化过程不稳定甚至无法收敛；学习率越小，神经网络的参数更新越慢，但可能会导致优化过程过于缓慢或者陷入局部最优解。）
>
>   默认情况下，学习率的倍增器为 0.05、0.1 或 0.2，具体取决于最终 `batch_size`（较大的批次大小通常使用较大的学习率效果更好），建议尝试在 0.02 到 0.2 范围内实验不同值以找出产生最佳结果的值。
>
> - `prompt_loss_weight` （number，选填，默认是0.01）
>
>   "prompt_loss_weight" 是指在使用 Prompt-based Learning（基于提示的学习）方法进行训练时，用于调整提示损失（Prompt Loss）对总体损失（Total Loss）的相对权重。
>
>   Prompt-based Learning 是一种利用人类先验知识来辅助神经网络学习的方法，其中提示损失是指利用人类先验知识设计的提示（Prompt）与模型生成的结果之间的损失。
>
>   在 Prompt-based Learning 中，通过调整 prompt_loss_weight 的大小来平衡总体损失和提示损失的贡献，从而使模型更好地利用人类先验知识进行预测。如果 prompt_loss_weight 较大，模型会更加依赖提示损失，更好地利用人类先验知识；如果 prompt_loss_weight 较小，模型会更加依赖总体损失，更好地适应当前数据集的特征和分布。
>
> - `compute_classification_metrics` （boolean，选填，默认是false）
>
>   如果设置了，会在每个 epoch 结束时使用验证集计算特定于分类的指标，例如准确率和 F-1 分数。这些指标可以在 [微调结果文件](https://platform.openai.com/docs/guides/fine-tuning/analyzing-your-fine-tuned-model) 中查看。为了计算分类指标，必须提供一个`validation_file(验证文件)`。
>
>   此外，对于多类分类，必须指定 `classification_n_classes`；对于二元分类，则需要指定`classification_positive_class`。
>
> - `suffix` （string，选填，默认为 null）
>
>   一个长度最多为 40个字符 的字符串，将被添加到微调模型名称中。
>
>   例如，`suffix`  为 “custom-model-name” 会生成一个模型名称，如 `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`。


##### **List fine-tunes**
列出所属组织下的微调作业列表
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# GET https://api.openai.com/v1/fine-tunes
openai.FineTune.list()
```

**响应** ：
```json
{
  "object": "list",
  "data": [
    {
      "id": "ft-AF1WoRqd3aJAHsqc9NY7iL8F",
      "object": "fine-tune",
      "model": "curie",
      "created_at": 1614807352,
      "fine_tuned_model": null,
      "hyperparams": { ... },
      "organization_id": "org-...",
      "result_files": [],
      "status": "pending",
      "validation_files": [],
      "training_files": [ { ... } ],
      "updated_at": 1614807352,
    },
    { ... },
    { ... }
  ]
}
```

##### **Retrieve fine-tune**
获取有关微调作业的信息
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/fine-tunes/{fine_tune_id}
openai.FineTune.retrieve(id="ft-AF1WoRqd3aJAHsqc9NY7iL8F")
```

**响应** ：
```json
{
  "id": "ft-AF1WoRqd3aJAHsqc9NY7iL8F",
  "object": "fine-tune",
  "model": "curie",
  "created_at": 1614807352,
  "events": [
    {
      "object": "fine-tune-event",
      "created_at": 1614807352,
      "level": "info",
      "message": "Job enqueued. Waiting for jobs ahead to complete. Queue number: 0."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807356,
      "level": "info",
      "message": "Job started."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807861,
      "level": "info",
      "message": "Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807864,
      "level": "info",
      "message": "Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807864,
      "level": "info",
      "message": "Job succeeded."
    }
  ],
  "fine_tuned_model": "curie:ft-acmeco-2021-03-03-21-44-20",
  "hyperparams": {
    "batch_size": 4,
    "learning_rate_multiplier": 0.1,
    "n_epochs": 4,
    "prompt_loss_weight": 0.1,
  },
  "organization_id": "org-...",
  "result_files": [
    {
      "id": "file-QQm6ZpqdNwAaVC3aSz5sWwLT",
      "object": "file",
      "bytes": 81509,
      "created_at": 1614807863,
      "filename": "compiled_results.csv",
      "purpose": "fine-tune-results"
    }
  ],
  "status": "succeeded",
  "validation_files": [],
  "training_files": [
    {
      "id": "file-XGinujblHPwGLSztz8cPS8XY",
      "object": "file",
      "bytes": 1547276,
      "created_at": 1610062281,
      "filename": "my-data-train.jsonl",
      "purpose": "fine-tune-train"
    }
  ],
  "updated_at": 1614807865,
}
```

##### **Cancel fine-tune**
立即取消微调工作
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/fine-tunes/{fine_tune_id}/cancel
openai.FineTune.cancel(id="ft-AF1WoRqd3aJAHsqc9NY7iL8F")
```
**响应** ：
```json
{
  "id": "ft-xhrpBbvVUzYGo8oUO1FY4nI7",
  "object": "fine-tune",
  "model": "curie",
  "created_at": 1614807770,
  "events": [ { ... } ],
  "fine_tuned_model": null,
  "hyperparams": { ... },
  "organization_id": "org-...",
  "result_files": [],
  "status": "cancelled",
  "validation_files": [],
  "training_files": [
    {
      "id": "file-XGinujblHPwGLSztz8cPS8XY",
      "object": "file",
      "bytes": 1547276,
      "created_at": 1610062281,
      "filename": "my-data-train.jsonl",
      "purpose": "fine-tune-train"
    }
  ],
  "updated_at": 1614807789,
}
```

##### **List fine-tune events**
获取微调作业各阶段运行状态（事件）详情
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/fine-tunes/{fine_tune_id}/events
openai.FineTune.list_events(id="ft-AF1WoRqd3aJAHsqc9NY7iL8F")
```

**响应** ：
```json
{
  "object": "list",
  "data": [
    {
      "object": "fine-tune-event",
      "created_at": 1614807352,
      "level": "info",
      "message": "Job enqueued. Waiting for jobs ahead to complete. Queue number: 0."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807356,
      "level": "info",
      "message": "Job started."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807861,
      "level": "info",
      "message": "Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807864,
      "level": "info",
      "message": "Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT."
    },
    {
      "object": "fine-tune-event",
      "created_at": 1614807864,
      "level": "info",
      "message": "Job succeeded."
    }
  ]
}
```
**Query parameters** ：

> - `stream` （boolean，选填）
>
>   对于微调作业运行状态是否以事件流的方式返回
>
>   如果设置为 true，则会不断地输出微调作业运行最新状态信息，直到微调作业完成（成功、取消或失败）时，以 `data：[DONE]` 消息终止。
>
>   如果设置为 false，则仅返回到目前为止生成的事件。
>

##### **Delete fine-tune model**
删除微调的模型（前提是有权限）
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/models/{model}
openai.Model.delete("curie:ft-acmeco-2021-03-03-21-44-20")
```
**响应** ：
```json
{
  "id": "curie:ft-acmeco-2021-03-03-21-44-20",
  "object": "model",
  "deleted": true
}
```
#### Models 模型管理
列出并描述 API 中可用的各种模型，可以参考 [模型文档](https://platform.openai.com/docs/models) 以了解可用的模型以及它们之间的差异。

##### **列出模型**

列出当前可用的模型，并提供有关每个模型的基本信息，例如所有者和可用性。
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/models
openai.Model.list()
```

**响应**
：

```json
{
  "data": [
    {
      "id": "model-id-0",
      "object": "model",
      "owned_by": "organization-owner",
      "permission": [...]
    },
    {
      "id": "model-id-1",
      "object": "model",
      "owned_by": "organization-owner",
      "permission": [...]
    },
    {
      "id": "model-id-2",
      "object": "model",
      "owned_by": "openai",
      "permission": [...]
    },
  ],
  "object": "list"
}
```

##### **检索模型详情**
检索模型实例，提供有关模型的基本信息，例如所有者和权限。其中，`model` 为必填的字符串类型，用于此请求的模型的 ID。
```python
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
# https://api.openai.com/v1/models/{model}
openai.Model.retrieve("text-davinci-003")
```

**响应** ：

```json
{
  "id": "text-davinci-003",
  "object": "model",
  "owned_by": "openai",
  "permission": [...]
}
```

#### 其他
- [Images 图像](https://platform.openai.com/docs/api-reference/images)（图像生成API，DALL·E的能力已经落后于Stable Diffusion和Midjourney，使用场景不多）
- [Audio 音频](https://platform.openai.com/docs/api-reference/audio)（音频转换为文本API，Whisper模型已经开源，可以本地搭建使用）
- [Files 文件](https://platform.openai.com/docs/api-reference/files)（上传文档API，一般与微调等功能一起使用，不需要专门关注）
- [Edits 编辑](https://platform.openai.com/docs/api-reference/edits)（更新提示词API，对话补全接口已经覆盖了）
- [Moderations 审核](https://platform.openai.com/docs/api-reference/fine-tunes/delete-model) (内容审核API，如果模型识别到提示词违反了OpenAI的内容策略，会返回审核信息详情)
- Parameter details 参数细节（没有使用过）

### 微调（Fine-tuning）

### 嵌入（Embeddings）
#### 文本嵌入是什么
向量是一个有方向和长度的量，可以用数学中的坐标来表示。例如，可以用二维坐标系中的向量表示一个平面上的点，也可以用三维坐标系中的向量表示一个空间中的点。在机器学习中，向量通常用于表示数据的特征。

而文本嵌入是一种将文本这种离散数据映射到连续向量空间的方法，嵌入技术可以将高维的离散数据降维到低维的连续空间中，并保留数据之间的语义关系，从而方便进行机器学习和深度学习的任务。

例如：  
> "机器学习"表示为 [1,2,3]   
 "深度学习"表示为[2,3,3]  
 "英雄联盟"表示为[9,1,3]
>
> 使用余弦相似度（余弦相似度是一种用于衡量向量之间相似度的指标，可以用于文本嵌入之间的相似度）在计算机中来判断文本之间的距离： 

> “机器学习”与“深度学习”的距离：![](https://private.codecogs.com/gif.latex?cos%28%5CTheta_1%20%29%3D%5Cfrac%7B1*2+2*3+3*3%7D%7B%5Csqrt%7B1%5E2+2%5E2+3%5E3%7D%5Csqrt%7B2%5E2+3%5E2+3%5E3%7D%7D%3D0.97)
> 
> "机器学习”与“英雄联盟“的距离"：![](https://private.codecogs.com/gif.latex?cos%28%5CTheta_2%20%29%3D%5Cfrac%7B1*9+2*1+3*3%7D%7B%5Csqrt%7B1%5E2+2%5E2+3%5E3%7D%5Csqrt%7B9%5E2+1%5E2+3%5E3%7D%7D%3D0.56)
> 
> “机器学习”与“深度学习”两个文本之间的余弦相似度更高，表示它们在语义上更相似。

#### 文本嵌入算法
文本嵌入算法是指将文本数据转化为向量表示的具体算法，通常包括以下几个步骤：
- 分词：将文本划分成一个个单词或短语。
- 构建词汇表：将分词后的单词或短语建立词汇表，并为每个单词或短语赋予一个唯一的编号。
- 计算词嵌入：使用预训练的模型或自行训练的模型，将每个单词或短语映射到向量空间中。
- 计算文本嵌入：将文本中每个单词或短语的向量表示取平均或加权平均，得到整个文本的向量表示。

常见的文本嵌入算法包括 Word2Vec、GloVe、FastText 等。这些算法通过预训练或自行训练的方式，将单词或短语映射到低维向量空间中，从而能够在计算机中方便地处理文本数据。
#### 文本嵌入用途
文本嵌入用于测量文本字符串的相关性，通常用于：
- 搜索（结果按与查询字符串的相关性排序）
- 聚类（其中文本字符串按相似性分组）
- 推荐（推荐具有相关文本字符串的项目）
- 异常检测（识别出相关性很小的异常值）
- 多样性测量（分析相似性分布）
- 分类（其中文本字符串按其最相似的标签分类）

#### 使用文本嵌入模型
* 可以使用 HuggingFace上能够处理文本嵌入的开源模型，例如：[uer/sbert-base-chinese-nli](https://huggingface.co/uer/sbert-base-chinese-nli)
  ```python
  from sentence_transformers import SentenceTransformer
  model = SentenceTransformer('uer/sbert-base-chinese-nli')
  sentences = ["机器学习","深度学习","英雄联盟",]
  sentence_embeddings = model.encode(sentences)
  ```

* 使用之前介绍的 [OpenAI 文本嵌入API](#embeddings) 可以将文本转换为向量，OpenAI API提供了多个文本嵌入模型，[这篇博客](https://openai.com/blog/new-and-improved-embedding-mode)对它们的性能进行了比较，这里是性能最好的`text-embedding-ada-002`说明：

  | 模型名称               | 价格                     | 分词器       | 最大输入 token | 输出 |
  | ---------------------- | ------------------------ | ------------ | -------------- | ---- |
  | text-embedding-ada-002 | 1000 token/0.0004美元 | cl100k_base  | 8191           | 1536 |

* 使用[tiktoken](https://github.com/openai/tiktoken) 计算原始字符串对应的 token 数。
  ```python
  import tiktoken

  def num_tokens_from_string(string: str, encoding_name: str) -> int:
      """Returns the number of tokens in a text string."""
      encoding = tiktoken.get_encoding(encoding_name)
      num_tokens = len(encoding.encode(string))
      return num_tokens

  num_tokens_from_string("tiktoken is great!", "cl100k_base")
  ```
#### 矢量数据库
* 为了快速搜索多个矢量，建议使用矢量数据库，下面是一些可选的矢量数据库：
  - [Pinecone](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/pinecone)，一个完全托管的矢量数据库
  - [Weaviate](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/weaviate)，一个开源的矢量搜索引擎
  - [Redis](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/redis)作为矢量数据库
  - [Qdrant](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/qdrant)，一个矢量搜索引擎
  - [Milvus](https://github.com/openai/openai-cookbook/blob/main/examples/vector_databases/Using_vector_databases_for_embeddings_search.ipynb)，一个为可扩展的相似性搜索而构建的矢量数据库
  - [Chroma](https://github.com/chroma-core/chroma)，一个开源嵌入式商店
  - [Typesense](https://typesense.org/docs/0.24.0/api/vector-search.html)，快速的开源矢量搜索引擎
  - [Zilliz](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/zilliz)，数据基础设施，由Milvus提供技术支持
  - [FAISS](https://github.com/facebookresearch/faiss) 是Meta开源的用于高效搜索大规模矢量数据集的库
* 性能✍️：和传统数据库一样，可以使用工程手段优化矢量数据库搜索性能，最直接的就是更新索引算法 ，对索引数据进行分区优化，将数据通过“沃罗诺伊图单元”（也被叫做泰森多边形）来进行切割（类似传统数据库分库分表）。
1. 平面索引（FLAT）

- 含义：将向量简单地存储在一个平面结构中，最基本的向量索引方法。
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$
- 余弦相似度（Cosine Similarity）：$sim(x,y) = \frac{x \cdot y}{\|x\| \|y\|}$

2. 分区索引（IVF）

- 含义：将向量分配到不同的分区中，每个分区建立一个倒排索引结构，最终通过倒排索引实现相似度搜索。
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$
- 余弦相似度（Cosine Similarity）：$sim(x,y) = \frac{x \cdot y}{\|x\| \|y\|}$

3. 量化索引（PQ）

- 含义：将高维向量划分成若干子向量，将每个子向量量化为一个编码，最终将编码存储在倒排索引中，利用倒排索引进行相似度搜索。
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$
- 汉明距离（Hamming Distance）：$d(x,y) = \sum_{i=1}^n (x_i \oplus y_i)$，其中 $\oplus$ 表示按位异或操作。

4. HNSW (Hierarchical Navigable Small World)

- 含义：通过构建一棵层次化的图结构，从而实现高效的相似度搜索。
- 内积（Inner Product）：$sim(x,y) = x \cdot y$
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$

5. NSG (Navigating Spreading-out Graph)

- 含义：通过构建一个分层的无向图来实现快速的相似度搜索。
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$

6. Annoy (Approximate Nearest Neighbors Oh Yeah)

- 含义：通过将高维空间的向量映射到低维空间，并构建一棵二叉树来实现高效的近似最近邻搜索。
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$
- 曼哈顿距离（Manhattan Distance）：$d(x,y) = \sum_{i=1}^n |x_i - y_i|$

7. LSH (Locality-Sensitive Hashing)

- 含义：通过使用哈希函数将高维的向量映射到低维空间，并在低维空间中比较哈希桶之间的相似度，实现高效的相似度搜索。
- 内积（Inner Product）：$sim(x,y) = x \cdot y$
- 欧式距离（Euclidean Distance）：$d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$


### GPT 最佳实践

#### 最佳安全实践

#### 最佳生产实践

### 参考链接
1. [OpenAI 文档](https://platform.openai.com/docs/introduction)
2. [OpenAI Cookbook](https://github.com/openai/openai-cookbook)：分享了使用OpenAI API完成常见任务的示例代码

